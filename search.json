[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Tidbits",
    "section": "",
    "text": "The motivation for these posts often comes from trying to google a question or topic related to coding, only to find little-to-no answer. Should I find a way to answer it myself, I‚Äôll post a ‚ÄúHow to‚Äù here with the hope that it helps other people with similar questions and/or becomes raw data on which LLMs can train. üê¢\n\n\n\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nReplace text within all cells of a specific column in R\n\n\nHere‚Äôs how to target specific column(s) in a data.frame or tibble to replace text within.\n\n\n\nR\n\nstringr\n\ndplyr\n\ntidyverse\n\ndata-cleaning\n\n\n\n\n\n\nJun 27, 2020\n\n\nVikram B. Baliga\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\nSearching for sequences on GenBank - a few tips and tricks\n\n\nSome things I‚Äôve learned from performing searches for DNA sequences on GenBank.\n\n\n\nGenBank\n\nDNA\n\ntree-inference\n\nphylogeny\n\nfasta\n\n\n\n\n\n\nJun 13, 2020\n\n\nVikram B. Baliga\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nSample variance at small sample sizes II: distributions\n\n\nHow does sample size affect the distribution of sample variance?\n\n\n\nR\n\nvariance\n\nsample-size\n\n\n\n\n\n\nMay 12, 2019\n\n\nVikram B. Baliga\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\nWhen is sample variance is a unreliable estimate of population variance?\n\n\nEmpirically showing that show that sample variance has high variance at low sample sizes\n\n\n\nR\n\nvariance\n\nsample-size\n\n\n\n\n\n\nMay 5, 2019\n\n\nVikram B. Baliga\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\nParallel processing for MCMCglmm in R (Windows-friendly)\n\n\nI set up a virtual cluster and then use the parallel::parLapply() function to run iterations of MCMCglmm() in parallel for computers running Windows.\n\n\n\nR\n\nMCMCglmm\n\nparallel\n\nparallel-processing\n\nWindows\n\n\n\n\n\n\nMay 3, 2019\n\n\nVikram B. Baliga\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\nCheck if packages are installed (and install if not) in R\n\n\nHere‚Äôs some code that provides an easy way to check whether specific packages are in the default Library. If they are, they‚Äôre simply loaded via library(). If any packages are missing, they‚Äôre installed (with dependencies) into the default Library and are then loaded.\n\n\n\nR\n\npackages\n\npackage-installation\n\npackage-loading\n\n\n\n\n\n\nApr 28, 2019\n\n\nVikram B. Baliga\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nSet max DLLs in R (Windows)\n\n\nIf you need to adjust the max number of .dll files that R can handle, here is code that works if you are using Windows.\n\n\n\nR\n\nDLLs\n\nWindows\n\n\n\n\n\n\nApr 22, 2019\n\n\nVikram B. Baliga\n\n1 min\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "All courses taught at UBC unless otherwise noted. Content for each course is within the specific Canvas site for each term (accessible to enrolled students and teaching team only), but syllabi are available via the links below."
  },
  {
    "objectID": "teaching.html#upcoming-courses",
    "href": "teaching.html#upcoming-courses",
    "title": "Teaching",
    "section": "Upcoming courses",
    "text": "Upcoming courses\n\n2025W2\n\nBIOL 300: Fundamentals of Biostatistics Sections 201 and 202 (jointly with Darren Irwin)\n\n\n\n2025W1\n\nBIOL 300: Fundamentals of Biostatistics Section 101 (jointly with Kaitlyn Gaynor)"
  },
  {
    "objectID": "teaching.html#courses-taught",
    "href": "teaching.html#courses-taught",
    "title": "Teaching",
    "section": "Courses taught",
    "text": "Courses taught\n\n2025S2\n\nBIOL 300: Fundamentals of Biostatistics Section 951 (Coordinator; Instructor is Mike Whitlock)\n\n\n\n2024W1\n\nBIOL 300: Fundamentals of Biostatistics Section 101\n\n\n\n2019W1\n\nSCIE 300: Communicating Science Section 111"
  },
  {
    "objectID": "press.html",
    "href": "press.html",
    "title": "Press",
    "section": "",
    "text": "Discovering the key to birds‚Äô agility could improve drone design\nUBC Science\nMarch 9, 2022\n\n\n\n\n\n\n\n\nEvolution of bird maneuverability and lessons for UAV design\nUniversity of Michigan Engineering\nMarch 9, 2022\n\n\n\n\n\n\n\n\nBuilding a better airplane by borrowing from birds\nCrosscut‚Äôs Human Elements\nApril 19, 2020\n\n\n\n\n\n\n\n\nBeaty Biodiversity Museum‚Äôs Researchers Revealed\nUBC Biodiversity Centre\nFebruary 24, 2020"
  },
  {
    "objectID": "press.html#video-segments",
    "href": "press.html#video-segments",
    "title": "Press",
    "section": "",
    "text": "Discovering the key to birds‚Äô agility could improve drone design\nUBC Science\nMarch 9, 2022\n\n\n\n\n\n\n\n\nEvolution of bird maneuverability and lessons for UAV design\nUniversity of Michigan Engineering\nMarch 9, 2022\n\n\n\n\n\n\n\n\nBuilding a better airplane by borrowing from birds\nCrosscut‚Äôs Human Elements\nApril 19, 2020\n\n\n\n\n\n\n\n\nBeaty Biodiversity Museum‚Äôs Researchers Revealed\nUBC Biodiversity Centre\nFebruary 24, 2020"
  },
  {
    "objectID": "press.html#articles",
    "href": "press.html#articles",
    "title": "Press",
    "section": "Articles",
    "text": "Articles\nScientific American: Hummingbirds Control Their Flight with a Newfound Mechanism; March 19, 2024.\nPhysOrg: Need for speed: How hummingbirds switch mental gears in flight; January 10, 2024. Also covered by UBC Science, ScienceDaily, and Popular Science.\nThe University of Michigan: Avian secret: The key to agile bird flight is switching quickly between stable and unstable gliding; March 9, 2022. Also covered by Phys.org, Canadian News Media, Head Topics, and Gamers Grade.\nUBC Science: Discovering the key to birds‚Äô agility could improve drone design; March 9, 2022.\nNature News and Views (written by Dr.¬†Aimy Wissa): Trade-offs between stability and manoeuvrability in bird flight; March 7, 2022.\nThe Michigan Engineer News Center: Bird-like wings could help drones keep stable in gusts; June 10, 2021.\nJournal of Experimental Biology - Outside JEB: Wing swing, not shape, is key to bird flight; February 3, 2020.\nThe Wildlife Society: Bird wing study reveals different flight development paths; November 15, 2019.\nVet Candy: Why are bald eagles such great gliders?; November 3, 2019.\nTechnology Org: Scientists are trying to figure out how birds hover, soar and glide; October 31, 2019.\nNature has no boss: Swimming through the air; October 31, 2019.\nThe Scientist: Image of the Day: Flight Styles; October 25, 2019.\nUnited Press International (UPI): An eagle‚Äôs gliding ability relies on its wrist movements; October 24, 2019. Also covered by Brietbart, Space Daily and News of the Day.\nCosmos Magazine: Birds wing it in many ways; October 24, 2019.\nCBC Radio-Canada: Le myst√®re entourant les styles de vol des oiseaux pourrait √™tre r√©solu (in French); October 24, 2019.\nLa Presse: Les myst√®res des ailes d‚Äôoiseaux (in French); October 24, 2019.\nBeaty Biodiversity Museum News & Stories: Rethinking wings; October 23, 2019.\nEurekAlert! (AAAS): Why are bald eagles such great gliders? It‚Äôs all in the wrist; October 23, 2019. Also covered by Science Daily, PhysOrg, and UBC News. Featured image on EurekAlert!\nEngineering.com: Gull Wing Morphing Research Aims to Enhance Flight Design; January 10, 2019.\nEnvironmental News Network: A better way to fly? Researchers study birds and their wings; January 9, 2019.\nThe Hindu: Inspired by seagull‚Äôs wings; January 9, 2019.\nUniversity of Toronto News: A better way to fly? U of T and UBC researchers study birds and their wings; January 7, 2019.\nThe Times (UK): Gulls‚Äô bendy wings point way ahead for smarter drones; January 3, 2019.\nEurekAlert! (AAAS): Could gulls‚Äô wings inspire smarter airplane design?; January 3, 2019. Also covered by AlphaGalileo and Lab Manager.\nSciTech Europa: How studying gulls‚Äô wings could improve aircraft design; January 3, 2019.\nThe Tribune (India): Seagull wings may inspire smarter airplane design; January 3, 2019. Also covered by The New Indian Express.\nNews Center Maine: Gull ‚Äòwing morphing‚Äô could be the future of airplane tech; Video by Amaze Lab; January 3, 2019.\nBusiness Standard: Gull‚Äôs wings may help design smarter airplanes; January 3, 2019. Also covered by Hindustan Times, Canindia News, and Newkerala.com.\nScience Daily: Engineers, zoologists reveal how gulls ‚Äòwing morph‚Äô for stable soaring; January 2, 2019. Also covered by Tech Xplore.\nNRC Handelsblad: Wiebelende meeuw stabiliseert zich met slim ellebogenwerk (in German); January 2, 2019."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vikram B. Baliga",
    "section": "",
    "text": "Dept. page\n ¬† UBC Zoology\n ¬† Email\n ¬† @vbaliga\n\n\n\n\n ¬† Google Scholar\n ¬† ORCID\n ¬† ResearchGate\n ¬† Publons"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Vikram B. Baliga",
    "section": "Welcome",
    "text": "Welcome\nI am an Assistant Professor of Teaching in the Department of Zoology at UBC, with a special focus on Biostatistics and Data Science.\nIn the recent past, I was a scientist (also at UBC) whose work focused on animal locomotion, vision, and evolutionary biology. My research asked how musculoskeletal and visual systems allow animals to control complex motion. This means that I used motion capture and virtual reality to investigate animals‚Äô locomotor behaviors, and examined the evolution of anatomy & physiology to understand mechanisms and limitations.\nData from behavioral or physiological studies tend to be extremely noisy. Making sense of information in these diverse data sets made me appreciate statistical methods and the design of effective visualizations. I also realized one of my favorite things to do is to work with people through these types of problems. This led me to embrace the analytical aspects of my job and look for opportunities to teach.\nAs an Assistant Professor, I now teach and/or coordinate BIOL 300: Fundamentals of Biostatistics regularly at UBC. Future teaching efforts may relate to DSCI 100 or courses that blend biology, statistics, and data science.\nüê¢"
  },
  {
    "objectID": "posts/2019-05-03-parallel-processing-for-mcmcglmm-in-r-windows-friendly/index.html",
    "href": "posts/2019-05-03-parallel-processing-for-mcmcglmm-in-r-windows-friendly/index.html",
    "title": "Parallel processing for MCMCglmm in R (Windows-friendly)",
    "section": "",
    "text": "Lately, I have been using the MCMCglmm package to run linear mixed-models in a Bayesian framework. The documentation is generally very good but there seems to be relatively little support for using parallel processing (here: using multiple cores on your machine) to efficiently run large volumes of mcmc runs. This is especially true for Windows users, who cannot use functions like parallel::mclapply().\nI‚Äôm happy to share that I have worked out a solution using the parallel package. Basically, I set up a virtual cluster and then use the parallel::parLapply() function to run iterations of MCMCglmm() in parallel."
  },
  {
    "objectID": "posts/2019-05-03-parallel-processing-for-mcmcglmm-in-r-windows-friendly/index.html#data",
    "href": "posts/2019-05-03-parallel-processing-for-mcmcglmm-in-r-windows-friendly/index.html#data",
    "title": "Parallel processing for MCMCglmm in R (Windows-friendly)",
    "section": "Data",
    "text": "Data\nI‚Äôll use ‚ÄúExample 2‚Äù from the MCMCglmm() function help. You can skip ahead to the next section if instead you‚Äôd like to tailor this to your own data & analysis.\nFirst load (or install&load) the MCMCglmm and parallel packages:\n\n## If a package is installed, it will be loaded. If any \n## are not, the missing package(s) will be installed \n## from CRAN and then loaded.\n\n## First specify the packages of interest\npackages = c(\"MCMCglmm\", \"parallel\")\n\n## Now load or install&load all\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n    }\n  }\n)\n\nWith the packages loaded, we‚Äôll prep our data set. Lifting this directly from the MCMCglmm() help page:\n\ndata(bird.families)\nphylo.effect &lt;- rbv(bird.families, 1, nodes = \"TIPS\")\nphenotype &lt;- phylo.effect + rnorm(dim(phylo.effect)[1], 0, 1)\n\n# simulate phylogenetic and residual effects\n# with unit variance\ntest.data &lt;- data.frame(phenotype = phenotype,\n                        taxon = row.names(phenotype))\nAinv &lt;- inverseA(bird.families)$Ainv\n\n# inverse matrix of shared phyloegnetic history\nprior &lt;- list(R = list(V = 1, nu = 0.002), \n              G = list(G1 = list(V = 1, nu = 0.002)))\n\nmodel2 &lt;- MCMCglmm(\n  phenotype ~ 1,\n  random =  ~ taxon,\n  ginverse = list(taxon = Ainv),\n  data = test.data,\n  prior = prior,\n  verbose = FALSE,\n  nitt = 1300,\n  burnin = 300,\n  thin = 1\n)\nsummary(model2)\n\n Iterations = 301:1300\n Thinning interval  = 1\n Sample size  = 1000 \n\n DIC: 375.0159 \n\n G-structure:  ~taxon\n\n\n R-structure:  ~units\n\n\n Location effects: phenotype ~ 1 \n\n            post.mean l-95% CI u-95% CI eff.samp pMCMC\n(Intercept)    0.1630  -0.5899   0.8938     1000 0.654\nOf course, the example provided sets nitt to only 1300, yielding an ESS of only ~800 for the fixed effect. I am guessing this is intended to make sure the example is quick to run.\nBoosting this to nitt = 100000, burnin = 10000, and thin = 10 gives a more healthy ESS &gt; 8000. But please note that this will take a lot longer to finish (I‚Äôll leave it up to you to use the Sys.time() function to time it yourself)."
  },
  {
    "objectID": "posts/2019-05-03-parallel-processing-for-mcmcglmm-in-r-windows-friendly/index.html#run-mcmc-chains-in-parallel",
    "href": "posts/2019-05-03-parallel-processing-for-mcmcglmm-in-r-windows-friendly/index.html#run-mcmc-chains-in-parallel",
    "title": "Parallel processing for MCMCglmm in R (Windows-friendly)",
    "section": "Run MCMC chains in parallel",
    "text": "Run MCMC chains in parallel\nWhenever conducting MCMC-based analyses, it‚Äôs advisable to conduct multiple runs (different chains) and then assess convergence. I‚Äôll leave the convergence assessments for another day (but here‚Äôs a good StackExchange post). For now we‚Äôll just conduct 10 runs of this model, each using nitt = 100000, using parallel processing.\nPLEASE NOTE: I am setting this up to use only 80% of your machine‚Äôs total logical processors. You can certainly harness all of your CPUs if you‚Äôd like, although I advise against doing so if any of your MCMC runs take more than a few minutes. It also doesn‚Äôt make sense to set the number of logical processors to be greater than the number of runs (chains), but more on that later. Anyway, treat your silicon well!\n\n# use detectCores() by itself if you want all CPUs\nsetCores &lt;- round(detectCores() * 0.8)\n\n# make the cluster\ncl &lt;- makeCluster(getOption(\"cl.cores\", setCores))\n  # EDIT ON 2020-07-27: I have been informed that Mac users \n  # may have better luck using:\n  # cl &lt;- parallel::makeCluster(getOption(\"cl.cores\", setCores), \n  #                             setup_strategy = \"sequential\")\n  # This is due to an apparent issue in RStudio. \n  # See this stackoverflow page for details:\n  # https://stackoverflow.com/questions/61700586/r-makecluster-command-used-to-work-but-now-fails-in-rstudio\n\n# load the MCMCglmm package within the cluster\ncl.pkg &lt;- clusterEvalQ(cl, library(MCMCglmm))\n\n# import each object that's necessary to run the function\nclusterExport(cl, \"prior\")\nclusterExport(cl, \"test.data\")\nclusterExport(cl, \"Ainv\")\n\n# use parLapply() to execute 10 runs of MCMCglmm()\n# each with nitt=100000\nmodel2_10runs &lt;- parLapply(cl = cl, 1:10, function(i) {\n  MCMCglmm(\n    phenotype ~ 1,\n    random =  ~ taxon,\n    ginverse = list(taxon = Ainv),\n    data = test.data,\n    prior = prior,\n    verbose = FALSE,\n    nitt = 100000,\n    burnin = 10000,\n    thin = 10\n  )\n})\n\n# once it's finished, use stopCluster() to stop running\n# the parallel cluster\nstopCluster(cl)\n\nThe model2_10runs object is a list that contains each of the 10 mcmc models. You can perform all the usual summarization, plotting‚Ä¶etc, but just be sure to specify models within the list, e.g.: summary(model2_10runs[[3]]) to summarize the third model out of the 10\n Iterations = 10001:99991\n Thinning interval  = 10\n Sample size  = 9000 \n\n DIC: 109.7491 \n\n G-structure:  ~taxon\n\n      post.mean l-95% CI u-95% CI eff.samp\ntaxon     1.782   0.3085    2.989    178.6\n\n R-structure:  ~units\n\n      post.mean  l-95% CI u-95% CI eff.samp\nunits    0.4437 0.0001843    1.224    181.1\n\n Location effects: phenotype ~ 1 \n\n            post.mean l-95% CI u-95% CI eff.samp pMCMC\n(Intercept)    0.1697  -0.5989   0.9841     9000 0.666\nAs I mentioned above, we‚Äôll leave convergence and other fun topics like autocorrelation for another day.\nThat‚Äôs all!\nüê¢"
  },
  {
    "objectID": "posts/2019-05-05-variance-vs-sample-size/index.html",
    "href": "posts/2019-05-05-variance-vs-sample-size/index.html",
    "title": "When is sample variance is a unreliable estimate of population variance?",
    "section": "",
    "text": "Sample variance generally gives an unbiased estimate of the true population variance, but that does not mean it is a reliable estimate of population variance. Here, I show that sample variance itself has high variance at low sample sizes.\nFirst, we‚Äôll create a normally-distributed parent population with a known mean, variance, and sample size. This represents a natural population of something we‚Äôd like to study but for sake of time, money, or feasibility, we cannot measure everything. Our goal is to figure out how reliable smaller samples are with respect to estimates of variance. We‚Äôll take increasingly larger samples from this population and see how sample variance fares.\nmean = 0\nSD = 20 # Therefore population variance should be ~ 400. \n# We'll set population size low-ish for sake of \n# computational time\npopsize = 1000 \n\nset.seed(123) # reproducibility\n# generate the parent population\npop &lt;- rnorm(popsize, mean, SD)\n\n# Determine the true population variance.\n# It may be different from SD^2, since we are simulating\n# from a normal distribution\nvar(pop)\n\n[1] 393.3836\n\n# Now create a sequence from 1 to popsize\n# in increments of 1\nNs &lt;- seq(1, popsize, 1)\n# Within a sample size, we'll create 1000 replicates\n# to help us generalize our findings\nreps = 1000\n\n# The var() function takes n-1 in the denominator to give\n# a less biased estimator of population variance. We also\n# need a function to give the variance if we've got the \n# whole population.\nvar.p &lt;- function(x) {\n  var(x) * (length(x) - 1) / length(x)\n}"
  },
  {
    "objectID": "posts/2019-05-05-variance-vs-sample-size/index.html#how-does-sample-variance-behave",
    "href": "posts/2019-05-05-variance-vs-sample-size/index.html#how-does-sample-variance-behave",
    "title": "When is sample variance is a unreliable estimate of population variance?",
    "section": "How does sample variance ‚Äòbehave‚Äô?",
    "text": "How does sample variance ‚Äòbehave‚Äô?\nUsing our sequence of increasing sample size (Ns), we‚Äôll now create a matrix of variances. Each row number will correspond to its sample size. E.g. all values in row [50,] are variances from random samples of n = 50 taken from the parent population. Therefore, samples in row [1000,] should be identical and equal to the parent population‚Äôs variance, since we are drawing all 1000 samples from the parent population.\nThis process is repeated 1000 (reps) times for each sample size.\n\n# This may take some time.\nmymat = matrix(nrow = length(Ns), ncol = reps)\nfor (i in 1:dim(mymat)[1])\n{\n  for (j in 1:dim(mymat)[2])\n  {\n    mymat[i, j] = var(sample(pop, Ns[i]))\n  }\n}\nrownames(mymat) &lt;- seq(1, length(Ns))\n\n# By definition, all the values in row [1,] will be \"NA\", \n# since variance cannot be computed for N = 1. \n# So we'll just remove the row.\nmymat[-1, ] -&gt; varmat \n\nIt‚Äôs always good to visualize data. We‚Äôll first plot these raw estimates of variance.\n\n# Sample size will be on the x-axis\n# and sample variance will be on the y.\n# For a given sample size, 1000 reps were performed.\nplot(\n  rep(2, ncol(varmat)),\n  mymat[2, ],\n  ylim = c(0, max(varmat)),\n  xlim = c(0, nrow(mymat)),\n  pch = 19,\n  col = rgb(0, 0, 0, alpha = 0.2),\n  xlab = 'sample size',\n  ylab = 'sample variance',\n  tck = 0.02,\n  bty = \"n\"\n)\nfor (i in 3:nrow(mymat)) {\n  points(rep(i, ncol(varmat)),\n         mymat[i, ],\n         pch = 19,\n         col = rgb(0, 0, 0, alpha = 0.2))\n}\n\n# True population variance is ~ 400.\nabline(h = var.p(pop),\n       col = rgb(0, 0, 1, alpha = 0.5),\n       lwd = 3)\n\n# Compute the mean of sample variance at each sample size\n# and add it to the plot.\nlines(2:popsize, rowMeans(varmat),\n      col = 'orange', lwd = 3)\n\n# Add a legend\nlegend(400, 1500, \n       legend=c(\"True population variance\",\n                \"Means of sample variance\"),\n       col=c(rgb(0, 0, 1, alpha = 0.5), \"orange\"), \n       lty=1, lwd=3, box.lty=0)\n\n\n\n\n\n\n\n\nPretty crazy! The variation in sample variance is tremendous at small sample sizes. But the mean of this variation (orange) is basically identical to the true population variance (blue).\nLet‚Äôs figure out at what point the variance of sample variances seem to become reliable. Since we know this happens at small sample sizes, we‚Äôll just plot cases where sample size varies from 1 to 100 to get a more refined view of the data.\n\n# Create a function to calculate the variances of sampled \n# variance across all the replicates.\nRowVar &lt;- function(x) {\n  rowSums((x - rowMeans(x))^2)/(dim(x)[2] - 1)\n}\n\n# Variance of sample variances at each sample size\nRowVar(varmat)-&gt;varz\n\n# Plot of variance of variance at each sample size\n# Again, this is only for sample size &lt;= 100.\nplot(\n  varz[1:(length(pop) / 10)],\n  pch = 19,\n  col = rgb(0, 0, 0, alpha = 0.2),\n  xlab = 'sample size',\n  ylab = 'variance of sample variance',\n  tck = 0.02,\n  bty = \"n\"\n)\n\n\n\n\n\n\n\n\nThis trend reminds me of what we see in scree plots when conducting PCA or in elbow plots when trying to determine the optimal number of clusters. The difficulty in applying those methods is that there isn‚Äôt an underlying covariance structure here (at least one that I can think of) that we‚Äôd be able to tease apart.\nFortunately, there is a package called changepoint that finds ‚Äúchangepoints‚Äù in series of data (based on shifts in either values or variance). Let‚Äôs implement the changepoint::cpt.var() function to identify a potential point where sample variances seem to stabilize.\n\ninstall.packages(\"changepoint\")\n\nThe following package(s) will be installed:\n- changepoint [2.2.4]\nThese packages will be installed into \"~/Library/CloudStorage/OneDrive-UBC/github_repos/vbaliga.github.io/renv/library/R-4.4/aarch64-apple-darwin20\".\n\n# Installing packages --------------------------------------------------------\n- Installing changepoint ...                    OK [linked from cache]\nSuccessfully installed 1 package in 3.5 milliseconds.\n\nlibrary(changepoint)\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nSuccessfully loaded changepoint package version 2.2.4\n See NEWS for details of changes.\n\n# Plot again\nplot(\n  varz,\n  pch = 19,\n  col = rgb(0, 0, 0, alpha = 0.2),\n  xlab = 'sample size',\n  ylab = 'variance of sample variance',\n  tck = 0.02,\n  bty = \"n\"\n)\n\n# At what sample size do we see stability?\nabline(v = cpt.var(varz[1:(length(varz) - 1)])@cpts[1],\n       col = rgb(1, 0, 0, alpha = 0.8), lty=2)\ntext(\n  x = cpt.var(varz[1:(length(varz) - 1)])@cpts[1] + 5,\n  y = 0.5 * varz[1],\n  pos = 4,\n  paste(cpt.var(varz[1:(length(varz)-1)])@cpts[1],\n        \"samples\")\n)\n\n\n\n\n\n\n\n\nThe vertical red line shows the sample size after which the variance of sample variance tends to be relatively low."
  },
  {
    "objectID": "posts/2019-05-05-variance-vs-sample-size/index.html#can-we-find-general-patterns",
    "href": "posts/2019-05-05-variance-vs-sample-size/index.html#can-we-find-general-patterns",
    "title": "When is sample variance is a unreliable estimate of population variance?",
    "section": "Can we find general patterns?",
    "text": "Can we find general patterns?\nAt what point is sample size large enough to trust its estimation of the true variance? Let‚Äôs first see if it depends on the parent population‚Äôs actual variance.\nWe‚Äôll create a few other examples and see if we can find common patterns. We‚Äôll fix population means at 0, population sizes to be 1000 but vary standard deviations (and therefore variance) widely.\n\nmean = 0\nreps = 1000\n\n# Specify our SDs and set popsize to 1000 in each case.\nparams &lt;- expand.grid(SD = c(0.1, 0.5, 1, 2, 5,\n                             10, 50, 100),\n                      popsize = 1000)\n\n# This function takes all the steps we did in the \n# previous analysis and function-izes it.\nvarSamplr &lt;- function(SD, popsize) {\n  pop &lt;- rnorm(popsize, mean, SD)\n  Ns &lt;- seq(1, popsize, 1)\n  \n  mymat = matrix(nrow = length(Ns), ncol = reps)\n  for (i in 1:dim(mymat)[1])\n  {\n    for (j in 1:dim(mymat)[2])\n    {\n      mymat[i, j] = var(sample(pop, Ns[i]))\n    }\n  }\n  rownames(mymat) &lt;- seq(1, length(Ns))\n  mymat[-1, ] -&gt; varmat\n  RowVar(varmat)-&gt;varz\n  \n  plot(\n    varz,\n    pch = 19,\n    col = rgb(0, 0, 0, alpha = 0.2),\n    xlab = 'sample size',\n    ylab = 'variance of sample variance',\n    tck = 0.02,\n    bty = \"n\",\n    main = paste(\n      \"N = \",\n      popsize,\n      \"; \",\n      \"SD = \",\n      SD,\n      \"\\nrelative stability at \",\n      cpt.var(varz[1:(length(varz) - 1)])@cpts[1],\n      \" samples\",\n      sep = \"\")\n  )\n\n  # At what sample size do we see stability?\n  abline(\n    v = cpt.var(varz[1:(length(varz) - 1)])@cpts[1],\n    col = rgb(1, 0, 0, alpha = 0.8),\n    lty = 2\n  )\n}\n\n# Organize so we can multi-plot\npar(mfrow = c(4, 2))\n\n# Run. This will take some time.\nfor (i in 1:nrow(params)) {\n  print(i)\n  varSamplr(params[i, 1], params[i, 2])\n}\n\n[1] 1\n\n\n[1] 2\n\n\n[1] 3\n\n\n[1] 4\n\n\n[1] 5\n\n\n[1] 6\n\n\n[1] 7\n\n\n[1] 8\n\n\n\n\n\n\n\n\n\nPretty interesting! Although the standard deviation varies widely across these data sets (from 0.1 to 100), taking samples of size 1 through ~ 46 leaves us vulnerable to the dangers of the left side of the curve. So we‚Äôre seeing that samples of &lt; 4-5% of the true population size are relatively unreliable.\nOf course, the changepoint metric does also seem a little conservative. It might be worthwhile thinking of another way to find the point of relative stability."
  },
  {
    "objectID": "posts/2019-05-05-variance-vs-sample-size/index.html#does-population-size-matter",
    "href": "posts/2019-05-05-variance-vs-sample-size/index.html#does-population-size-matter",
    "title": "When is sample variance is a unreliable estimate of population variance?",
    "section": "Does population size matter?",
    "text": "Does population size matter?\nOne more thing I‚Äôd like to determine is if our results so far stem from fixing the population size at 1000. So, we‚Äôll repeat this but instead of varying standard deviation, we‚Äôll vary population size.\n\nmean = 0\nreps = 1000\n\n# This time SD is set to 1 and popsize varies\nparams &lt;- expand.grid(SD = 1,\n                      popsize = c(50, 100, 200, 500,\n                                  1000, 2000, 3500,\n                                  5000))\n\n# Organize so we can multi-plot\npar(mfrow = c(4, 2))\n\n# Run. This will take some time.\nfor (i in 1:nrow(params)) {\n  print(i)\n  varSamplr(params[i, 1], params[i, 2])\n}\n\n[1] 1\n\n\n[1] 2\n\n\n[1] 3\n\n\n[1] 4\n\n\n[1] 5\n\n\n[1] 6\n\n\n[1] 7\n\n\n[1] 8\n\n\n\n\n\n\n\n\n\nSo it seems that as true population size increases, so too does the location of the changepoint. Let‚Äôs plot this more explicitly:\n\npops &lt;- c(50, 100, 200, 500, 1000, 2000, 3500, 5000)\ncps &lt;- c(5, 7, 13, 25, 46, 79, 130, 172)\n\nplot(\n  pops,\n  cps,\n  pch = 19,\n  col = rgb(0, 0, 0, alpha = 0.8),\n  xlab = 'population size',\n  ylab = 'changepoint of sample variance',\n  tck = 0.02,\n  bty = \"n\"\n)\n\n\n\n\n\n\n\n\nIndeed it seems there is a direct (log-linear?) relationship. I‚Äôm sure this is covered by theory - perhaps somehow by the law of large numbers or the CTL. One hunch I have is that as population size decreases, our distributions get farther away from an ideal, infinitely-sized population.\nIn any case, the shape of the curve is pretty consistent across all these empirical trials. We can confidently conclude that we should not trust sample variance at low sample sizes. What remains to be seen is how ‚Äúsmall‚Äù is too small\nThat‚Äôs all!\nüê¢"
  },
  {
    "objectID": "posts/2020-06-13-genbank-searches-tips-and-tricks/index.html",
    "href": "posts/2020-06-13-genbank-searches-tips-and-tricks/index.html",
    "title": "Searching for sequences on GenBank - a few tips and tricks",
    "section": "",
    "text": "This will be a ‚Äúlow-tech‚Äù post, i.e.¬†one that doesn‚Äôt showcase code.\nOver the past few years, I‚Äôve done a lot of searches for genetic sequences on GenBank with the endgame of building phylogenetic trees. Here‚Äôs a list of things that have & haven‚Äôt worked for me when it has come to the task of finding specific genes for specific taxa.\nA few good ways to set up the search term for nuclear genes are (ordered by specificity):\n\n(Genus_species) NOT (whole genome) NOT predicted\n(Genus_species) NOT (whole genome) NOT predicted NOT mitochondri\\*\n(Genus_species) NOT (whole genome) NOT predicted NOT mitochondri\\*\n\nNote 1: I always avoid including sequences that have the word ‚Äúpredicted‚Äù in the title; I‚Äôd rather rely on sequences that have established identity. That said, including NOT predicted can be dangerous as the word ‚Äúpredicted‚Äù may appear e.g.¬†in the title of the corresponding paper, but the sequence itself may be known with more certainty.\nNote 2: For similar reasons, NOT (whole genome) may fare better than NOT genome\nNote 3: OR needs to be nested within parenthetical statements. Taking the third bullet point as an example, a search without the the parentheses surrounding the OR statement such as (Genus_species) NOT (whole genome) NOT predicted NOT mitochondri* AND gene1 OR gene2 would amount to searching for (Genus_species) NOT (whole genome) NOT predicted NOT mitochondri* AND gene1 OR gene2. Therefore, all cases of gene2 for every species ever would appear in the search results!\nPerhaps this list of notes will grow more someday, but that‚Äôs all for now.\nüê¢"
  },
  {
    "objectID": "posts/2020-06-27-replace-text-in-specific-column/index.html",
    "href": "posts/2020-06-27-replace-text-in-specific-column/index.html",
    "title": "Replace text within all cells of a specific column in R",
    "section": "",
    "text": "Recently, I needed to find a way to rename specific cells within one column of a tibble without affecting cells in other columns. I knew that stringr::str_replace() is awesome for this sort of thing, but I hadn‚Äôt quite grasped how I could target specific columns with it.\nFortunately,dplyr::mutate_at(), and newer mechanisms via dplyr::across(), seem to fit the bill. I‚Äôll run through a few examples in this post.\nWe‚Äôll start by loading tidyverse:\nlibrary(tidyverse) ## I'm  using v1.3.0.9000"
  },
  {
    "objectID": "posts/2020-06-27-replace-text-in-specific-column/index.html#the-data",
    "href": "posts/2020-06-27-replace-text-in-specific-column/index.html#the-data",
    "title": "Replace text within all cells of a specific column in R",
    "section": "The data",
    "text": "The data\nWe‚Äôll now generate an example tibble to work with which we will simply call data.\nCode to make this object will be appended to the end of this post so we can get to the punchline faster. Look down there if you‚Äôd like to re-create this example fully on your own\nHere‚Äôs how data looks:\n\ndata\n\n# A tibble: 100 √ó 5\n   subject       treatment      var1   var2   var3\n   &lt;chr&gt;         &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 subject_c 003 treatment z  0.452  0.464  0.231 \n 2 subject_c 003 treatment y  0.0412 0.165  0.350 \n 3 subject_c 003 treatment y -0.422  0.585  0.605 \n 4 subject_b 003 treatment z -2.05   0.271  0.453 \n 5 subject_c 003 treatment x  1.13   0.230  0.447 \n 6 subject_b 003 treatment x -1.46   0.691  0.413 \n 7 subject_b 003 treatment z  0.740  0.283  0.0504\n 8 subject_b 003 treatment y  1.91   0.810  0.587 \n 9 subject_c 003 treatment y -1.44   0.0939 0.433 \n10 subject_a 003 treatment y  0.702  0.822  0.121 \n# ‚Ä¶ with 90 more rows"
  },
  {
    "objectID": "posts/2020-06-27-replace-text-in-specific-column/index.html#the-issue",
    "href": "posts/2020-06-27-replace-text-in-specific-column/index.html#the-issue",
    "title": "Replace text within all cells of a specific column in R",
    "section": "The issue",
    "text": "The issue\nNow say we want to replace the contents of data$subject with something less tedious. Right now, each subject name has 003 appended to it and we‚Äôd like to shave these parts off the names.\nstringr::str_replace() is great for replacing text that fits a specified criterion. So we could simply tell str_replace() to target instances of 003 within the subject column. But the object fed into str_replace() needs to be a vector, which can be awkward to pull from a tibble. Moreover, we‚Äôd like to do this safely and ensure that no other columns in the tibble are affected."
  },
  {
    "objectID": "posts/2020-06-27-replace-text-in-specific-column/index.html#use-mutate_at-with-str_replace",
    "href": "posts/2020-06-27-replace-text-in-specific-column/index.html#use-mutate_at-with-str_replace",
    "title": "Replace text within all cells of a specific column in R",
    "section": "Use mutate_at() with str_replace()",
    "text": "Use mutate_at() with str_replace()\nFortunately, I found that dplyr::mutate_at() can help us target column(s) of interest (here subject) and leave other columns untouched.\n\nrenamed_data &lt;- \n  data %&gt;% \n  mutate_at(\"subject\", str_replace, \" 003\", \"\")\nrenamed_data\n\n# A tibble: 100 x 5\n  subject   treatment      var1   var2   var3\n  &lt;chr&gt;     &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 subject_c treatment z  0.452  0.464  0.231 \n2 subject_c treatment y  0.0412 0.165  0.350 \n3 subject_c treatment y -0.422  0.585  0.605 \n4 subject_b treatment z -2.05   0.271  0.453 \n5 subject_c treatment x  1.13   0.230  0.447 \n6 subject_b treatment x -1.46   0.691  0.413 \n7 subject_b treatment z  0.740  0.283  0.0504\n8 subject_b treatment y  1.91   0.810  0.587 \n9 subject_c treatment y -1.44   0.0939 0.433 \n10 subject_a treatment y  0.702  0.822  0.121 \n# ‚Ä¶ with 90 more rows\nNice!\nBy using dplyr::mutate_at(), we are specifiying that str_replace() should target the subject column only and take all instances of 003 and replace them with nothing (\"\").\nFor those who prefer to not use pipes, we can accomplish the same thing by specifying data as the first argument in mutate_at().\n\nrenamed_data_no_pipe &lt;- \n  mutate_at(data, \"subject\", str_replace, \" 003\", \"\")\nrenamed_data_no_pipe\n\n# A tibble: 100 x 5\n   subject   treatment      var1   var2   var3\n   &lt;chr&gt;     &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 subject_c treatment z  0.452  0.464  0.231 \n 2 subject_c treatment y  0.0412 0.165  0.350 \n 3 subject_c treatment y -0.422  0.585  0.605 \n 4 subject_b treatment z -2.05   0.271  0.453 \n 5 subject_c treatment x  1.13   0.230  0.447 \n 6 subject_b treatment x -1.46   0.691  0.413 \n 7 subject_b treatment z  0.740  0.283  0.0504\n 8 subject_b treatment y  1.91   0.810  0.587 \n 9 subject_c treatment y -1.44   0.0939 0.433 \n10 subject_a treatment y  0.702  0.822  0.121 \n# ‚Ä¶ with 90 more rows"
  },
  {
    "objectID": "posts/2020-06-27-replace-text-in-specific-column/index.html#use-mutate-and-across-with-str_replace",
    "href": "posts/2020-06-27-replace-text-in-specific-column/index.html#use-mutate-and-across-with-str_replace",
    "title": "Replace text within all cells of a specific column in R",
    "section": "Use mutate() and across() with str_replace()",
    "text": "Use mutate() and across() with str_replace()\nI should note that the _at component of dplyr has now been considered ‚Äúsuperseded‚Äù. Instead, the authors of dplyr recommend we use dplyr::across() to target our column(s) of interest. So we can write another version of the above:\n\nrenamed_data_across &lt;-\n  data %&gt;%\n  mutate(across(\"subject\", str_replace, \" 003\", \"\"))\nrenamed_data_across\n\n# A tibble: 100 x 5\n   subject   treatment      var1   var2   var3\n   &lt;chr&gt;     &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 subject_c treatment z  0.452  0.464  0.231 \n 2 subject_c treatment y  0.0412 0.165  0.350 \n 3 subject_c treatment y -0.422  0.585  0.605 \n 4 subject_b treatment z -2.05   0.271  0.453 \n 5 subject_c treatment x  1.13   0.230  0.447 \n 6 subject_b treatment x -1.46   0.691  0.413 \n 7 subject_b treatment z  0.740  0.283  0.0504\n 8 subject_b treatment y  1.91   0.810  0.587 \n 9 subject_c treatment y -1.44   0.0939 0.433 \n10 subject_a treatment y  0.702  0.822  0.121 \n# ‚Ä¶ with 90 more rows\nEither way, we are able to trim off the extra text in subject names and avoid the potential of affecting other columns."
  },
  {
    "objectID": "posts/2020-06-27-replace-text-in-specific-column/index.html#data",
    "href": "posts/2020-06-27-replace-text-in-specific-column/index.html#data",
    "title": "Replace text within all cells of a specific column in R",
    "section": "Data",
    "text": "Data\nHere‚Äôs the code that was used to create data:\n\nstrings_subs   &lt;- c(\"subject_a 003\", \"subject_b 003\", \"subject_c 003\")\nstrings_treats &lt;- c(\"treatment x\", \"treatment y\", \"treatment z\")\n\nset.seed(123)\ndata &lt;- \n  tibble::tibble(subject   = sample(strings_subs,   100, replace = TRUE),\n                 treatment = sample(strings_treats, 100, replace = TRUE),\n                 var1 = rnorm(100, 0, 1),\n                 var2 = runif(100, 0, 1),\n                 var3 = rbeta(100, 1, 1))\n\nThat‚Äôs all!\nüê¢"
  },
  {
    "objectID": "posts/2019-04-28-verify-that-r-packages-are-installed-and-loaded/index.html",
    "href": "posts/2019-04-28-verify-that-r-packages-are-installed-and-loaded/index.html",
    "title": "Check if packages are installed (and install if not) in R",
    "section": "",
    "text": "Say you have an R script that you share with others. You may not be sure that each user has installed all the packages the script will require. Using install.packages() would be unnecessary for users who already have the packages and simply need to load them.\nHere‚Äôs some code that provides an easy way to check whether specific packages are in the default Library. If they are, they‚Äôre simply loaded via library(). If any packages are missing, they‚Äôre installed (with dependencies) into the default Library and are then loaded."
  },
  {
    "objectID": "posts/2019-04-28-verify-that-r-packages-are-installed-and-loaded/index.html#load-install-load-packages",
    "href": "posts/2019-04-28-verify-that-r-packages-are-installed-and-loaded/index.html#load-install-load-packages",
    "title": "Check if packages are installed (and install if not) in R",
    "section": "Load | install & load packages",
    "text": "Load | install & load packages\n\n## If a package is installed, it will be loaded. If any \n## are not, the missing package(s) will be installed \n## from CRAN and then loaded.\n\n## First specify the packages of interest\npackages = c(\"MASS\", \"nlme\")\n\n## Now load or install&load all\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n    }\n  }\n)\n\nThe logic of the package.check() function basically goes:\n\nUsing lapply() to the list of packages,\nIf a package is not installed, install it.\nOtherwise, load it.\n\nYou can then use search() to determine whether all the packages have loaded.\n\nsearch()\n\n [1] \".GlobalEnv\"        \"package:nlme\"      \"package:MASS\"     \n [4] \"package:stats\"     \"package:graphics\"  \"package:grDevices\"\n [7] \"package:datasets\"  \"renv:shims\"        \"package:utils\"    \n[10] \"package:methods\"   \"Autoloads\"         \"package:base\"     \n\n\nThat‚Äôs all!\nüê¢"
  },
  {
    "objectID": "posts/2019-04-22-set-max-DLLs-in-r/index.html",
    "href": "posts/2019-04-22-set-max-DLLs-in-r/index.html",
    "title": "Set max DLLs in R (Windows)",
    "section": "",
    "text": "On occasion, you may need adjust the max number of .dll files that R can handle. I first encountered this need when using a high number of packages together.\nI‚Äôve had trouble finding this info in the past, so I decided to create this post for others. This works if you are using Windows.\nThe following is machine-specific, so you will need to do this on each computer you run R."
  },
  {
    "objectID": "posts/2019-04-22-set-max-DLLs-in-r/index.html#find-the-.renviron-file",
    "href": "posts/2019-04-22-set-max-DLLs-in-r/index.html#find-the-.renviron-file",
    "title": "Set max DLLs in R (Windows)",
    "section": "Find the .Renviron file",
    "text": "Find the .Renviron file\n\nuser_renviron &lt;- \n  path.expand(file.path(\"~\", \".Renviron\"))\n# check to see if the file already exists\n# typically under: \"C:/Users/YOURUSERNAME/Documents/.Renviron\"\nif(!file.exists(user_renviron)) \n  file.create(user_renviron)\nfile.edit(user_renviron) \n\nIf file.edit(user_renviron) fails to work, just open the file itself (located wherever user_renviron is pointing) with a text editor."
  },
  {
    "objectID": "posts/2019-04-22-set-max-DLLs-in-r/index.html#edit-max-dlls",
    "href": "posts/2019-04-22-set-max-DLLs-in-r/index.html#edit-max-dlls",
    "title": "Set max DLLs in R (Windows)",
    "section": "Edit max DLLs",
    "text": "Edit max DLLs\nOnce you have the file open, edit or add the following line, save, and restart R:\n\nR_MAX_NUM_DLLS=500\n\nüê¢"
  },
  {
    "objectID": "posts/2019-05-12_variance-vs-sample-size-2/index.html",
    "href": "posts/2019-05-12_variance-vs-sample-size-2/index.html",
    "title": "Sample variance at small sample sizes II: distributions",
    "section": "",
    "text": "In a previous post, I showed that although sample variance, on average, gives an unbiased estimate of population variance, it is highly unreliable at extremely small sample sizes.\nThis time, I will focus more closely on the distribution of sample variance. How does sample size seem to affect the distribution of sample variance? And how might this inform how we determine which sample sizes are too small? I‚Äôll use one of my favorite new(ish) packages, ggridges, to plot the sets of distributions from one example simulation."
  },
  {
    "objectID": "posts/2019-05-12_variance-vs-sample-size-2/index.html#behavior-of-sample-variance-at-small-sample-sizes.",
    "href": "posts/2019-05-12_variance-vs-sample-size-2/index.html#behavior-of-sample-variance-at-small-sample-sizes.",
    "title": "Sample variance at small sample sizes II: distributions",
    "section": "‚ÄòBehavior‚Äô of sample variance at small sample sizes.",
    "text": "‚ÄòBehavior‚Äô of sample variance at small sample sizes.\nI‚Äôll first re-create part of what I showed in my previous post but on a different scale. We‚Äôll simulate a dataset for a ‚Äòparent‚Äô population and then take many random samples of increasingly larger sample sizes to get a sense of how sample variance behaves.\nTo cut down on time, I will only take samples at particular sample sizes, based on the sample sizes which seemed interesting (to me!) in the previous post.\nI‚Äôll keep this code tucked away so we can move quickly. Click the text below to see all the code if you‚Äôd like.\n\nmean = 0\nSD = 20\npopsize = 1000\n\nset.seed(123) # to get the same parent pop as last time\npop &lt;- rnorm(popsize, mean, SD)\n\n# verify that we get the same variance as last time\nvar(pop)\n\n[1] 393.3836\n\n# pick specific Ns this time\nNs &lt;- c(2, 3, 5, 10, 15, 30, 45, \n        90, 180, 250, 500, 750)\nreps = 1000\n\nvar.p &lt;- function(x) {\n  var(x) * (length(x) - 1) / length(x)\n}\n\n# Please note that I don't use set.seed() here.\n# So these samples will not be identical to those we\n# got in mymat & varmat last time.\nvarmat = matrix(nrow = length(Ns), ncol = reps)\nfor (i in 1:dim(varmat)[1])\n{\n  for (j in 1:dim(varmat)[2])\n  {\n    varmat[i, j] = var(sample(pop, Ns[i]))\n  }\n}\nrownames(varmat) &lt;- Ns\n\nplot(\n  rep(2, ncol(varmat)),\n  varmat[1,],\n  ylim = c(0, max(varmat)),\n  xlim = c(0, (max(Ns) + 50)),\n  pch = 19,\n  col = rgb(0, 0, 0, alpha = 0.2),\n  xlab = 'sample size',\n  ylab = 'sample variance',\n  tck = 0.02,\n  bty = \"n\"\n)\nfor (i in 2:length(Ns)) {\n  points(rep(Ns[i], ncol(varmat)),\n         varmat[i,],\n         pch = 19,\n         col = rgb(0, 0, 0, alpha = 0.2))\n}\nabline(h = var.p(pop),\n       col = rgb(0, 0, 1, alpha = 0.5),\n       lwd = 3)\npoints(Ns, rowMeans(varmat),\n       col = 'orange', pch = 19)\nlegend(300, 3000, \n       legend=c(\"True population variance\",\n                \"Means of sample variance\"),\n       col=c(rgb(0, 0, 1, alpha = 0.5), \"orange\"), \n       lty=1, lwd=3, box.lty=0)\n\n\n\n\n\n\n\nplot(\n  rep(2, ncol(varmat)),\n  varmat[1,],\n  ylim = c(0, max(varmat)),\n  xlim = c(0, 15),\n  pch = 19,\n  col = rgb(0, 0, 0, alpha = 0.2),\n  xlab = 'sample size',\n  ylab = 'sample variance',\n  tck = 0.02,\n  bty = \"n\"\n)\nfor (i in 2:length(Ns)) {\n  points(rep(Ns[i], ncol(varmat)),\n         varmat[i,],\n         pch = 19,\n         col = rgb(0, 0, 0, alpha = 0.2))\n}\nabline(h = var.p(pop),\n       col = rgb(0, 0, 1, alpha = 0.5),\n       lwd = 3)\npoints(Ns, rowMeans(varmat),\n       col = 'orange', pch = 19)\nlegend(5, 4000, \n       legend=c(\"True population variance\",\n                \"Means of sample variance\"),\n       col=c(rgb(0, 0, 1, alpha = 0.5), \"orange\"), \n       lty=1, lwd=3, box.lty=0)\n\n\n\n\n\n\n\n\nThis looks generally similar to the first figure from my previous post. The parent population is identical to the one I used previous, as I called set.seed(123) prior to each simulation. But I did not use set.seed() prior to sampling from the parent, which means that varmat will be different each time.\nIt may be hard to see what‚Äôs going on at the smallest sample sizes, so here‚Äôs the data at sample size &gt;= 15:\nOf course, it‚Äôs (hopefully) very likely that no published study would try to say anything conclusive about population variance based on a sample size of 2 or 3."
  },
  {
    "objectID": "posts/2019-05-12_variance-vs-sample-size-2/index.html#distributions-of-sample-variance-at-each-sample-size",
    "href": "posts/2019-05-12_variance-vs-sample-size-2/index.html#distributions-of-sample-variance-at-each-sample-size",
    "title": "Sample variance at small sample sizes II: distributions",
    "section": "Distributions of sample variance at each sample size",
    "text": "Distributions of sample variance at each sample size\nWe‚Äôll now take a look at how the distributions of sample variance at each sample size (i.e.¬†each vertical strip) vary.\n\n# First load | install&load packages we'll need\npackages = c(\"ggplot2\", \"ggridges\", \"tidyr\", \n             \"forcats\", \"dplyr\",\"viridis\")\n# See this post for info on this code chunk\npackage.check &lt;- lapply(\n  packages,\n  FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n      install.packages(x, dependencies = TRUE)\n      library(x, character.only = TRUE)\n    }\n  }\n)\n\n\nThe downloaded binary packages are in\n    /var/folders/8k/s3cltr015b37qj74wmpvcgmc0000gn/T//Rtmpka5HEp/downloaded_packages\n\nThe downloaded binary packages are in\n    /var/folders/8k/s3cltr015b37qj74wmpvcgmc0000gn/T//Rtmpka5HEp/downloaded_packages\n\n# Re-organize our data in tidy format\ndf &lt;- tidyr::gather(as.data.frame(t(varmat)))\n# Sorting data so it appears on the y-axis in the \n# correct order is tricky in ggplot2.\n# We'll use dplyr::mutate() with forcats::fct_relevel()\n# to re-organize the data prior to plotting\ndf %&gt;% mutate(key = fct_relevel(key, as.character(Ns))) -&gt; df\n\n# Use ggplot() with ggridges::geom_density_ridges2()\n# The coord_flip() argument flips the axes so they are\n# in the same orientation as in the previous figure.\np &lt;- ggplot(df, aes(x = value, y = key)) +\n  geom_vline(\n    xintercept = var.p(pop),\n    col = rgb(0, 0, 1, alpha = 0.5),\n    lwd = 1\n  ) +\n  geom_density_ridges2(\n    rel_min_height = 0.001,\n    scale = 2,\n    fill = rgb(0, 0, 0, alpha = 0.75)\n  ) +\n  coord_flip() +\n  ylab(\"sample size\") + xlab(\"sample variance\") +\n  \n  theme_ridges()\np\n\n\n\n\n\n\n\nmedianz&lt;-apply(varmat,1,median)\nmeanz&lt;-apply(varmat,1,mean)\n\nplot(\n  Ns,\n  meanz,\n  pch = 19,\n  col = \"#42AB5D\",\n  xlab = \"sample size\",\n  ylab = \"value\",\n  ylim = c(0, (max(meanz) + 100)),\n  xlim = c(0, (max(Ns) + 50)),\n  tck = 0.02,\n  bty = \"n\"\n)\npoints(\n  Ns,\n  medianz,\n  pch = 19,\n  col = \"#DD3497\",\n  ylab = \"value\",\n  xlab = \"sample size\"\n)\nabline(h = var.p(pop),\n       col = rgb(0, 0, 1, alpha = 0.5),\n       lwd = 3)\nlegend(\n  300,\n  200,\n  legend = c(\"Means of sample variance\",\n             \"Medians of sample variance\"),\n  col = c(\"#42AB5D\", \"#DD3497\"),\n  pch = 19,\n  box.lty = 0\n)\n\n\n\n\n\n\n\n\nAt small sample sizes, we see extremely skewed distributions of sample variance. For sample size = 15 or below (among our cherry-picked examples), we‚Äôre seeing extremely long right-tailed distributions. The shapes of the distributions indicate that median and/or mode might strongly differ from the mean sample variance. Let‚Äôs take a look.\nWe‚Äôll just focus on median vs.¬†mean:\nSo at small sample sizes, the means of sample variance are close to but overshoop our population variance, whereas the medians sharply underestimate population variance.\nBut at sample sizes over 45, means and medians of sample variance are nearly identical to the true population variance.\n\n# not added\nEnvStats::epdfPlot(varmat[12, ],\n                   xlim = c(-500, 1500),\n                   epdf.col = viridis(12)[12])\nfor (i in 11:1) {\n  EnvStats::epdfPlot(varmat[i, ],\n                     epdf.col = viridis(12)[i], \n                     add = TRUE)\n}\n\n\n\n\n\n\n\n\nüê¢"
  },
  {
    "objectID": "data-software-code.html",
    "href": "data-software-code.html",
    "title": "Data, software & code",
    "section": "",
    "text": "Many of the links below will take you to content on GitHub (@vbaliga) or Figshare (see my profile here)."
  },
  {
    "objectID": "data-software-code.html#r-packages",
    "href": "data-software-code.html#r-packages",
    "title": "Data, software & code",
    "section": "R packages",
    "text": "R packages\n\navinertia: Calculate the inertial properties of a flying bird\navinertia provides tools to compute the center of gravity and moment of inertia tensor of any flying bird. The tools function by modeling a bird as a composite structure of simple geometric objects. This requires detailed morphological measurements of bird specimens although those obtained for the associated paper have been included in the package for use. Written with Christina A. Harvey and Jasmin C.M. Wong.\nAccompanying paper (Harvey et al., 2022) in Nature\n\n\n\npathviewr: Tools to import, clean, and visualize animal movement data in R\n\nPart of the rOpenSci project (github: ropensci/pathviewr)\npathviewr offers tools to import, clean, and visualize movement data, particularly from motion capture systems such from Optitrack‚Äôs Motive, the Straw Lab‚Äôs Flydra, or from other sources. We provide functions to remove artifacts, standardize tunnel position and tunnel axes, select a region of interest, isolate specific trajectories, fill gaps in trajectory data, and calculate 3D and per-axis velocity. For experiments of visual guidance, we also provide functions that use subject position to estimate perception of visual stimuli. Written with Melissa S. Armstrong and Eric R. Press.\n\n\n\ngaussplotR: Fit, predict, and plot 2D Gaussians in R\n\ngaussplotR provides functions to fit two-dimensional Gaussian functions, predict values from such functions, and produce plots of predicted data.\nAccompanying paper (Baliga, 2021) in the Journal of Open Source Software\n\n\n\nworkloopR: Analysis of work loops and other data from muscle physiology experiments in R\n\nPart of the rOpenSci project (github: ropensci/workloopR)\nworkloopR (pronounced ‚Äúwork looper‚Äù) provides functions for the import, transformation, and analysis of muscle physiology experiments in R. Over the course of developing the package, we expanded this goal to also cover experiments that are often complementary to the work loop technique. Written with Shree Senthivasan.\nAccompanying paper (Baliga and Senthivasan, 2019) in the Journal of Open Source Software\n\n\n\ngenbank_downloadR: Batch downloading of DNA or protein sequences from GenBank\nwritten as a standalone R script rather than as a full-blown package. Stable releases also available on Figshare."
  },
  {
    "objectID": "data-software-code.html#tutorials",
    "href": "data-software-code.html#tutorials",
    "title": "Data, software & code",
    "section": "Tutorials",
    "text": "Tutorials\n\nMulti-panel plots with R\nDeveloped for BIOL 548L (Visual and Oral Presentations), graduate course at UBC\nLearning objectives:\n\nDetermine how to import & wrangle data from diverse sources\nUse the grammar of graphics to construct plots in ggplot2\nPlan a sequence of plots that support a declarative statement of a result\nConstruct multi-panel, publication-quality figures using code"
  },
  {
    "objectID": "data-software-code.html#data-code-from-pubs",
    "href": "data-software-code.html#data-code-from-pubs",
    "title": "Data, software & code",
    "section": "Data & code from pubs",
    "text": "Data & code from pubs\nSome of these repositories contain phylogenies that we‚Äôve inferred, but see the Phylogenetic trees section below for straightforward access to MCC & ML trees.\n\nfigshare repository for: Dash S, Baliga VB, Lapsansky AB, Wylie DR, and Altshuler DL. 2024. Encoding of global visual motion in the avian pretectum shifts from a bias for temporal-to-nasal selectivity to omnidirectional excitation across speeds. eNeuro.\nfigshare repository for: Baliga VB, Dakin R, Wylie DR, and Altshuler DL. 2024. Hummingbirds use distinct control strategies for forward and hovering flight. Proceedings of the Royal Society B: Biological Sciences.\nfigshare repository for: Smyth G, Baliga VB, Gaede AH, Wylie DR, and Altshuler DL. 2022. Specializations in optic flow encodingin the pretectum of hummingbirds and zebra finches. Current Biology.\nfigshare repository for: Harvey, CA, Baliga VB, Wong JCM, Altshuler DL, and Inman DJ. 2022. Birds can transition between stable and unstable states via wing morphing. Nature. (repository arranged & maintained by Christina Harvey)\nfigshare repository for: Harvey C, Baliga VB, Goates CD, Hunsaker D, and Inman DJ. 2021. Gull-inspired joint-driven wing morphing allows adaptive longitudinal flight control. Journal of the Royal Society Interface. (repository arranged & maintained by Christina Harvey)\nfigshare repository for: Leal PBC, Cabral-Seanez M, Baliga VB, Altshuler DL, and Hartl DJ. 2021. Phase transformation-driven artificial muscle mimics the multifunctionality of avian wing muscle. Journal of the Royal Society Interface. (repository arranged & maintained by Pedro Leal)\nfigshare repository for: Bahlman JW, Baliga VB, and Altshuler DL. 2020. Flight muscle power increases with strain amplitude and decreases with cycle frequency in zebra finches (Taeniopygia guttata). Journal of Experimental Biology.\nfigshare repository for: Baliga VB, Szabo I, and Altshuler DL. 2019. Range of motion in the avian wing is strongly associated with flight behavior and body mass. Science Advances.\ngithub repository for: Damsgaard C, Baliga VB, Bates E, Burggren W, McKenzie DJ, Taylor E, and Wright PA. 2019. Evolutionary and Cardio-Respiratory Physiology of Air-breathing and Amphibious Fishes. Acta Physiologica. (repository arranged & maintained by Christian Damsgaard)\nfigshare repository for: Baliga VB and Mehta RS. 2019. Morphology, ecology, and biogeography of independent origins of cleaning behavior around the world. Integrative and Comparative Biology.\nfigshare repository for: Harvey C, Baliga VB, Lavoie P, and Altshuler DL. 2019. Wing morphing allows gulls to modulate static pitch stability during gliding. Journal of the Royal Society Interface. (repository arranged & maintained by Christina Harvey)"
  },
  {
    "objectID": "data-software-code.html#phylogenetic-trees",
    "href": "data-software-code.html#phylogenetic-trees",
    "title": "Data, software & code",
    "section": "Phylogenetic trees",
    "text": "Phylogenetic trees\nI am generally happy to share trees from posterior distributions ‚Äî just shoot me an email\n\nBirds (Aves)\n\n222 taxa across Aves + outgroup; from Baliga et al.¬†2019 (Science Advances):\n\nBayesian MCC tree (download)\nMaximum likelihood tree (download)\n\n\n\n\nGobies (Gobiidae)\n\n54 species of Western Atlantic gobies + outgroup; from Baliga and Mehta 2019 (Integrative and Comparative Biology):\n\nBayesian MCC tree (download)\n\n\n\n\nMarine Angelfishes (Pomacanthidae)\n\n72 species of marine angelfishes + outgroup; from Baliga and Mehta 2019 (Integrative and Comparative Biology):\n\nBayesian MCC tree (download)\n\n\n\n\nWrasses & Parrotfishes (Labridae)\n\n344 species of wrasses + parrotfishes + outgroup; from Baliga and Law 2016 (Molecular Phylogenetics and Evolution):\n\nBayesian MCC tree (download)\nMaximum likelihood tree (download)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Altshuler DL, Baliga VB, Lapsansky AB, Lee P, Press ER, and Theriault JS. 2025. Understanding mechanisms of avian flight by integrating observations with tests of competing hypotheses. Journal of Experimental Biology. 228, jeb247992. doi:10.1242/jeb.247992\n\n\n\nDash S*, Baliga VB*, Lapsansky AB, Wylie DR, and Altshuler DL. 2024. Encoding of global visual motion in the avian pretectum shifts from a bias for temporal-to-nasal selectivity to omnidirectional excitation across speeds. eNeuro. doi:10.1523/ENEURO.0301-24.2024\n¬†¬†¬† * Equal contribution\nSkandalis DS, Baliga VB, Goller B, and Altshuler DL. 2024. The spatiotemporal richness of hummingbird wing deformations. Journal of Experimental Biology. 227, jeb246223. doi:10.1242/jeb.246223\nBaliga VB, Dakin R, Wylie DR, and Altshuler DL. 2024. Hummingbirds use distinct control strategies for forward and hovering flight. Proceedings of the Royal Society B: Biological Sciences. 291, 20232155. doi:10.1098/rspb.2023.2155\n\n\n\nSmyth G*, Baliga VB*, Gaede AH*, Wylie DR, and Altshuler DL. 2022. Specializations in optic flow encoding in the pretectum of hummingbirds and zebra finches. Current Biology. 32, 1-8. doi:10.1016/j.cub.2022.04.076\n¬†¬†¬† * Equal contribution\nHarvey CA, Baliga VB, Wong JCM, Altshuler DL, and Inman DJ. 2022. Birds can transition between stable and unstable states via wing morphing. Nature. 603, 648‚Äì653. doi:10.1038/s41586-022-04477-8\nGaede AH*, Baliga VB*, Smyth G, Guti√©rrez-Ib√°√±ez C, Altshuler DL, and Wylie DR. 2022. Response Properties of Optic Flow Neurons in the Accessory Optic System of Hummingbirds vs.¬†Zebra Finches and Pigeons. Journal of Neurophysiology. 127, 130-144. doi:10.1152/jn.00437.2021\n¬†¬†¬† ** Equal contribution\n\n\n\nLeal PBC, Cabral-Seanez M, Baliga VB, Altshuler DL, and Hartl DJ. 2021. Phase transformation-driven artificial muscle mimics the multifunctionality of avian wing muscle. Journal of the Royal Society Interface. 18, 20201042. doi:10.1098/rsif.2020.1042\nHarvey C, Baliga VB, Goates CD, Hunsaker D, and Inman DJ. 2021. Gull-inspired joint-driven wing morphing allows adaptive longitudinal flight control. Journal of the Royal Society Interface. 18, 20210132. doi:10.1098/rsif.2021.0132\n\n\n\nBahlman JW*, Baliga VB*, and Altshuler DL. 2020. Flight muscle power increases with strain amplitude and decreases with cycle frequency in zebra finches (Taeniopygia guttata). Journal of Experimental Biology. 223, jeb225839. doi:10.1242/jeb.225839\n¬†¬†¬† * Equal contribution\n\n\n\nBaliga VB, Szabo I, and Altshuler DL. 2019. Range of motion in the avian wing is strongly associated with flight behavior and body mass. Science Advances. 5, eaaw6670. doi:10.1126/sciadv.aaw6670\nDamsgaard C, Baliga VB, Bates E, Burggren W, McKenzie DJ, Taylor E, and Wright PA. 2019. Evolutionary and Cardio-Respiratory Physiology of Air-breathing and Amphibious Fishes. Acta Physiologica. 228, e13406. doi:10.1111/apha.13406\nBaliga VB and Mehta RS. 2019. Morphology, ecology, and biogeography of independent origins of cleaning behavior around the world. Integrative and Comparative Biology. 59, 625‚Äì637. doi:10.1093/icb/icz030\nHarvey C, Baliga VB, Lavoie P, and Altshuler DL. 2019. Wing morphing allows gulls to modulate static pitch stability during gliding. Journal of the Royal Society Interface. 16, 20180641. doi:10.1098/rsif.2018.0641\n\n\n\nBaliga VB and Mehta RS. 2018. Phylo-allometric analyses showcase the interplay between life history patterns and phenotypic convergence in cleaner wrasses. American Naturalist. 191, E129‚ÄìE143. doi:10.1086/697047\n\n\n\nBaliga VB, Bernstein ZJ*, Sundaram S*, and Mehta RS. 2017. Labrid cleaner fishes show kinematic convergence as juveniles despite variation in morphology. Journal of Experimental Biology. 220, 2787‚Äì2797. doi:10.1242/jeb.153783\n¬†¬†¬†* High school intern, UCSC-SIP\nDiluzio AR*, Baliga VB, Higgins BA, and Mehta RS. 2017. Effects of prey characteristics on the feeding behaviors of an apex marine predator, the California moray (Gymnothorax mordax). Zoology. 122, 80‚Äì89. doi:10.1016/j.zool.2017.03.002\n¬†¬†¬†* Undergraduate student\nLaw CJ, Baliga VB, Tinker MT, and Mehta RS. 2017. Asynchrony in craniomandibular development and growth in Enhydra lutris nereis (Carnivora: Mustelidae): are southern sea otters born to bite? Biological Journal of the Linnean Society. 121:3, 420‚Äì438. doi:10.1093/biolinnean/blw050\n\n\n\nBaliga VB and Mehta RS. 2016. Ontogenetic Allometry in Shape and Flexibility Underlies Life History Patterns of Labrid Cleaning Behavior. Integrative and Comparative Biology. 56:3, 416‚Äì427. doi:10.1093/icb/icw028\nBaliga VB and Law CJ. 2016. Cleaners among wrasses: Phylogenetics and evolutionary patterns of cleaning behavior within Labridae. Molecular Phylogenetics and Evolution. 94A, 424‚Äì435. doi:10.1016/j.ympev.2015.09.006\nBryce CM, Baliga VB, De Nesnera KL, Fiack D, Goetz K, Tarjan LM, Wade C, Yovovich V, Baumgart S*, Bard DG, Ash D, Parker IM, and Gilbert GS. 2016. Exploring Models in the Biology Classroom. The American Biology Teacher. 78:1, 35‚Äì42. doi:10.1525/abt.2016.78.1.35\n¬†¬†¬†* High school teacher\n\n\n\nBaliga VB and Mehta RS. 2015. Linking Cranial Morphology to Prey Capture Kinematics in Three Cleaner Wrasses: Labroides dimidiatus, Larabicus quadrilineatus, and Thalassoma lutescens. Journal of Morphology.¬†276, 1377‚Äì91. doi:10.1002/jmor.20425\n\n\n\nBaliga VB and Mehta RS. 2014. Scaling patterns inform ontogenetic transitions away from cleaning in Thalassoma wrasses. Journal of Experimental Biology. 217, 3597‚Äì3606. doi:10.1242/jeb.107680"
  },
  {
    "objectID": "publications.html#peer-reviewed-journal-articles",
    "href": "publications.html#peer-reviewed-journal-articles",
    "title": "Publications",
    "section": "",
    "text": "Altshuler DL, Baliga VB, Lapsansky AB, Lee P, Press ER, and Theriault JS. 2025. Understanding mechanisms of avian flight by integrating observations with tests of competing hypotheses. Journal of Experimental Biology. 228, jeb247992. doi:10.1242/jeb.247992\n\n\n\nDash S*, Baliga VB*, Lapsansky AB, Wylie DR, and Altshuler DL. 2024. Encoding of global visual motion in the avian pretectum shifts from a bias for temporal-to-nasal selectivity to omnidirectional excitation across speeds. eNeuro. doi:10.1523/ENEURO.0301-24.2024\n¬†¬†¬† * Equal contribution\nSkandalis DS, Baliga VB, Goller B, and Altshuler DL. 2024. The spatiotemporal richness of hummingbird wing deformations. Journal of Experimental Biology. 227, jeb246223. doi:10.1242/jeb.246223\nBaliga VB, Dakin R, Wylie DR, and Altshuler DL. 2024. Hummingbirds use distinct control strategies for forward and hovering flight. Proceedings of the Royal Society B: Biological Sciences. 291, 20232155. doi:10.1098/rspb.2023.2155\n\n\n\nSmyth G*, Baliga VB*, Gaede AH*, Wylie DR, and Altshuler DL. 2022. Specializations in optic flow encoding in the pretectum of hummingbirds and zebra finches. Current Biology. 32, 1-8. doi:10.1016/j.cub.2022.04.076\n¬†¬†¬† * Equal contribution\nHarvey CA, Baliga VB, Wong JCM, Altshuler DL, and Inman DJ. 2022. Birds can transition between stable and unstable states via wing morphing. Nature. 603, 648‚Äì653. doi:10.1038/s41586-022-04477-8\nGaede AH*, Baliga VB*, Smyth G, Guti√©rrez-Ib√°√±ez C, Altshuler DL, and Wylie DR. 2022. Response Properties of Optic Flow Neurons in the Accessory Optic System of Hummingbirds vs.¬†Zebra Finches and Pigeons. Journal of Neurophysiology. 127, 130-144. doi:10.1152/jn.00437.2021\n¬†¬†¬† ** Equal contribution\n\n\n\nLeal PBC, Cabral-Seanez M, Baliga VB, Altshuler DL, and Hartl DJ. 2021. Phase transformation-driven artificial muscle mimics the multifunctionality of avian wing muscle. Journal of the Royal Society Interface. 18, 20201042. doi:10.1098/rsif.2020.1042\nHarvey C, Baliga VB, Goates CD, Hunsaker D, and Inman DJ. 2021. Gull-inspired joint-driven wing morphing allows adaptive longitudinal flight control. Journal of the Royal Society Interface. 18, 20210132. doi:10.1098/rsif.2021.0132\n\n\n\nBahlman JW*, Baliga VB*, and Altshuler DL. 2020. Flight muscle power increases with strain amplitude and decreases with cycle frequency in zebra finches (Taeniopygia guttata). Journal of Experimental Biology. 223, jeb225839. doi:10.1242/jeb.225839\n¬†¬†¬† * Equal contribution\n\n\n\nBaliga VB, Szabo I, and Altshuler DL. 2019. Range of motion in the avian wing is strongly associated with flight behavior and body mass. Science Advances. 5, eaaw6670. doi:10.1126/sciadv.aaw6670\nDamsgaard C, Baliga VB, Bates E, Burggren W, McKenzie DJ, Taylor E, and Wright PA. 2019. Evolutionary and Cardio-Respiratory Physiology of Air-breathing and Amphibious Fishes. Acta Physiologica. 228, e13406. doi:10.1111/apha.13406\nBaliga VB and Mehta RS. 2019. Morphology, ecology, and biogeography of independent origins of cleaning behavior around the world. Integrative and Comparative Biology. 59, 625‚Äì637. doi:10.1093/icb/icz030\nHarvey C, Baliga VB, Lavoie P, and Altshuler DL. 2019. Wing morphing allows gulls to modulate static pitch stability during gliding. Journal of the Royal Society Interface. 16, 20180641. doi:10.1098/rsif.2018.0641\n\n\n\nBaliga VB and Mehta RS. 2018. Phylo-allometric analyses showcase the interplay between life history patterns and phenotypic convergence in cleaner wrasses. American Naturalist. 191, E129‚ÄìE143. doi:10.1086/697047\n\n\n\nBaliga VB, Bernstein ZJ*, Sundaram S*, and Mehta RS. 2017. Labrid cleaner fishes show kinematic convergence as juveniles despite variation in morphology. Journal of Experimental Biology. 220, 2787‚Äì2797. doi:10.1242/jeb.153783\n¬†¬†¬†* High school intern, UCSC-SIP\nDiluzio AR*, Baliga VB, Higgins BA, and Mehta RS. 2017. Effects of prey characteristics on the feeding behaviors of an apex marine predator, the California moray (Gymnothorax mordax). Zoology. 122, 80‚Äì89. doi:10.1016/j.zool.2017.03.002\n¬†¬†¬†* Undergraduate student\nLaw CJ, Baliga VB, Tinker MT, and Mehta RS. 2017. Asynchrony in craniomandibular development and growth in Enhydra lutris nereis (Carnivora: Mustelidae): are southern sea otters born to bite? Biological Journal of the Linnean Society. 121:3, 420‚Äì438. doi:10.1093/biolinnean/blw050\n\n\n\nBaliga VB and Mehta RS. 2016. Ontogenetic Allometry in Shape and Flexibility Underlies Life History Patterns of Labrid Cleaning Behavior. Integrative and Comparative Biology. 56:3, 416‚Äì427. doi:10.1093/icb/icw028\nBaliga VB and Law CJ. 2016. Cleaners among wrasses: Phylogenetics and evolutionary patterns of cleaning behavior within Labridae. Molecular Phylogenetics and Evolution. 94A, 424‚Äì435. doi:10.1016/j.ympev.2015.09.006\nBryce CM, Baliga VB, De Nesnera KL, Fiack D, Goetz K, Tarjan LM, Wade C, Yovovich V, Baumgart S*, Bard DG, Ash D, Parker IM, and Gilbert GS. 2016. Exploring Models in the Biology Classroom. The American Biology Teacher. 78:1, 35‚Äì42. doi:10.1525/abt.2016.78.1.35\n¬†¬†¬†* High school teacher\n\n\n\nBaliga VB and Mehta RS. 2015. Linking Cranial Morphology to Prey Capture Kinematics in Three Cleaner Wrasses: Labroides dimidiatus, Larabicus quadrilineatus, and Thalassoma lutescens. Journal of Morphology.¬†276, 1377‚Äì91. doi:10.1002/jmor.20425\n\n\n\nBaliga VB and Mehta RS. 2014. Scaling patterns inform ontogenetic transitions away from cleaning in Thalassoma wrasses. Journal of Experimental Biology. 217, 3597‚Äì3606. doi:10.1242/jeb.107680"
  },
  {
    "objectID": "publications.html#peer-reviewed-software-publications",
    "href": "publications.html#peer-reviewed-software-publications",
    "title": "Publications",
    "section": "Peer-reviewed software publications",
    "text": "Peer-reviewed software publications\n\n2021\nBaliga VB. 2021. gaussplotR: Fit, predict, and plot 2D-Gaussians in R. Journal of Open Source Software. 6:60, 3074. doi: 10.21105/joss.03074\n\n\n2019\nBaliga VB and Senthivasan S. 2019. workloopR: Analysis of work loops and other data from muscle physiology experiments in R. Journal of Open Source Software. 4:43, 1856. doi: 10.21105/joss.01856"
  },
  {
    "objectID": "publications.html#conference-papers",
    "href": "publications.html#conference-papers",
    "title": "Publications",
    "section": "Conference papers",
    "text": "Conference papers\nFull-length papers submitted in concert with conference presentations; not peer-reviewed\n\n2020\nHarvey C, Baliga VB, and Inman DJ. 2020. Control force required to morph the elbow and wrist in gulls. American Institute of Aeronautics and Astronautics Scitech 2020 Forum. Held January 6 - 10, 2020 in Orlando, FL. doi:10.2514/6.2020-1037\n\n\n2019\nHarvey C, Baliga VB, Altshuler DL, and Inman DJ. 2019. Pitch Control Effectiveness of the Avian Elbow and Wrist via a Numerical Lifting Line Analysis. American Institute of Aeronautics and Astronautics Scitech 2019 Forum (AIAA 2019-0853). Held January 7 - 11, 2019 in San Diego, CA. doi:10.2514/6.2019-0853"
  },
  {
    "objectID": "publications.html#inquiry-based-teaching-modules",
    "href": "publications.html#inquiry-based-teaching-modules",
    "title": "Publications",
    "section": "Inquiry-based teaching modules",
    "text": "Inquiry-based teaching modules\nAvailable at the SCWIBLES Modules page\n\n2014\nBaliga VB, and Yew B. 2014. Demystifying Dimensions: A mini-lesson on dimensional analysis. Product of GK-12 SCWIBLES, NSF DGE-0947923\n\nBaliga VB, Yew B, Herradora R, Callahan W. 2014. A Fact of Matter: Exploring trends across the Periodic Table. Product of GK-12 SCWIBLES, NSF DGE-0947923\nde Nesnera K, Baliga VB, et al.¬†2014. Presentation Skills: A video designed for science fair participants in high school. Product of GK‚Äì12 SCWIBLES, NSF DGE-0947923\nBaliga VB, and Baumgart S. 2014. A Matter of Human Proportions: Are you Vitruvian? Product of GK-12 SCWIBLES, NSF DGE-0947923\n\n\n2013\nBaliga VB, and Baumgart S. 2013. Hold Your Breath: What triggers the dive response in mammals? Product of GK-12 SCWIBLES, NSF DGE-0947923"
  }
]